\documentclass{beamer}
\usepackage{Sweave}
\usetheme{metropolis}

\title{A gentle introduction to Bayesian inference, MCMC, and Stan}
\subtitle{}
\author{Matt Espe}
\institute{University of California - Davis}
\date{\today}

\begin{document}
\maketitle

\begin{frame}{Outline}
\tableofcontents
\end{frame}

\section{Bayesian inference (crash course)}

\begin{frame}{Bayes Theorem}

  $$ P(\theta \mid X) = \frac{P(X \mid \theta) \, P(\theta)}{P(X)} $$

  $ P(\theta \mid X) $ is the posterior,

  $ P(X \mid \theta) $ is the likelihood,

  $ P(\theta) $ is the prior,

  $ P(X) $ is the support.
  
\end{frame}

\begin{frame}{Bayes Theorem (cont.)}

  $$ P(\theta \mid X) \propto P(X \mid \theta) \, P(\theta) $$

\end{frame}

\begin{frame}{The issue}

  For simple problems, we can analytically derive the posterior.
  
  More complicated models might not be analytically
  tractable.
  
  But, we can sample from $ P(\theta \mid X) $ even without knowing
  the analytical solution!
  
\end{frame}

\begin{frame}{MCMC}

  Markov Chain Monte Carlo (MCMC) is a method to sample from $
  P(\theta \mid X) $

  Many different algorithms with different strengths and weaknesses.
  
\end{frame}

\begin{frame}[fragile]{Random Walk Metropolis Hastings}

<<echo = TRUE, size = 'tiny'>>=
RWmetroNorm <- function(x, prior_mu, prior_sd, known_sd = 1,
                        step_size = 0.1, iter = 100)
{
      samples <- numeric(iter)
      samples[1] <- rnorm(1, prior_mu, prior_sd)
      
      for(i in 2:iter){
          prop <- rnorm(1, samples[i - 1], step_size)

          cur_ll <- sum(dnorm(x, samples[i - 1], sd = known_sd, log = TRUE)) +
              dnorm(samples[i - 1], prior_mu, prior_sd, log = TRUE)
          prop_ll <- sum(dnorm(x, prop, sd = known_sd, log = TRUE)) +
              dnorm(prop, prior_mu, prior_sd, log = TRUE)

          jump_prob <- min(exp(prop_ll - cur_ll), 1)

          if(runif(1) < jump_prob){
              samples[i] <- prop
          } else {
              samples[i] <- samples[i -1]
          }
      }
      return(samples)
  }

@ 
\end{frame}

\begin{frame}[fragile]{Random Walk MH (cont.)}

<<echo=FALSE, fig = TRUE, out.width='80%'>>=
x <- rnorm(25, 10, 1)
ans <- RWmetroNorm(x = x, prior_mu = 8, prior_sd = 0.5, iter = 1e5)

compareDens <- function(data, prior, post)
 {
     items <- list(density(data), density(prior), density(post))
     y_max <- max(sapply(items, function(x) max(x[['y']])))
     plot(items[[1]], type = "n", ylim = c(0,y_max), main = "")
     sapply(1:3, function(i) lines(items[[i]], lty = i, lwd=2))
     legend('topright', legend = c("Likelihood", "Prior", "Posterior"),
            lty = 1:3, lwd=2)
 }

compareDens(rnorm(1e5, mean(x), sd(x)), rnorm(1e5, 8, 0.5), ans)

@ 

\end{frame}

\begin{frame}[fragile]{JAGS}

<<size = 'tiny'>>=
library(rjags)
mod.text <- '
model{
  for( i in 1:N ){
    x[i] ~ dnorm(mu, (1/known_sd ^2))
    }
  mu ~ dnorm(prior_mu, (1/prior_sd^2))
}'
@

<<echo=FALSE, warning = FALSE>>=
m <- jags.model(textConnection(mod.text),
                data = list(x = x, N = length(x),
                            known_sd = 1,
                            prior_mu = 8,
                            prior_sd = 0.5))
jags.ans <- coda.samples(m, 'mu', n.iter = 1e5)

@ 
  
\end{frame}

\begin{frame}[fragile]{Let's break things}

<<size = 'tiny'>>=
x2 <- rnorm(25, x, sd = 0.1)
y <- rnorm(25, x * 2, 0.5)

mod2.text <- '
model{
  for( i in 1:N ){
    y[i] ~ dnorm(beta1 * x[i] + beta2 * x2[i], (1/known_sd ^2))
    }
  beta1 ~ dnorm(0, 1)
  beta2 ~ dnorm(0, 1)
}'
@

<<echo=FALSE, warning = FALSE>>=
m2 <- jags.model(textConnection(mod2.text),
                data = list(y = y, x = x, x2 = x2, N = length(x),
                            known_sd = 1), n.chains = 4)
jags.ans2 <- coda.samples(m2, c('beta1', 'beta2'), n.iter = 2000)

@   
  
\end{frame}  

\begin{frame}[fragile]{Difficult posteriors}

<<echo=FALSE, fig=TRUE, out.width='80%'>>=
par(mfrow = c(2,1))  
coda::traceplot(jags.ans2)
@ 

\end{frame}

\begin{frame}[fragile]{Enter Stan}

<<fig = TRUE, echo = FALSE, out.width = '80%'>>=
library(rstanarm)
stan.mod <- stan_glm(y ~ x + x2 - 1, prior = normal(), cores = 4L)
stan_trace(stan.mod)
@ 

\end{frame}

\begin{frame}[fragile]{Why does this break?}

<<fig=TRUE, out.width = '80%'>>=
cov(x,x2)
effectiveSize(jags.ans2)
summary(stan.mod, probs = 0.5)
pairs(stan.mod)
@


\end{frame}

\end{document}