\documentclass{beamer}
\usepackage{Sweave}
\usetheme{metropolis}

\title{A gentle introduction to Bayesian inference, MCMC, and Stan}
\subtitle{}
\author{Matt Espe}
\institute{Data Science Initiative, University of California - Davis}
\date{\today}

\begin{document}
\maketitle

\begin{frame}{Outline}
\tableofcontents
\end{frame}

\section{Bayesian inference (a crash course)}

\begin{frame}{Bayes Theorem}
%% setup
<<echo = FALSE, include = FALSE>>=
library(rstanarm)
library(rstan)
library(rjags)
set.seed(123)

@

  $$ P(\theta \mid X) = \frac{P(X \mid \theta) \, P(\theta)}{P(X)} $$

  \vfill

  $ P(\theta \mid X) $ is the posterior,

  \vfill

  $ P(X \mid \theta) $ is the likelihood,

  \vfill

  $ P(\theta) $ is the prior,

  \vfill

  $ P(X) $ is the support.
  
\end{frame}

\begin{frame}{Bayes Theorem (cont.)}

  $$ P(\theta \mid X) \propto P(X \mid \theta) \, P(\theta) $$

\end{frame}

\begin{frame}{Why Bayes?}

  It presents a coherent method to combine information from multiple sources.

  \vfill

  It is flexible.

  \vfill

  However, it will not save you from yourself!
  
\end{frame}

\begin{frame}{The issue with Bayes}

  For simple problems, we can analytically derive the posterior.

  \vfill
  
  More complicated models might not be analytically
  tractable.

  \vfill
  
  But, we can sample from $ P(\theta \mid X) $ even without knowing
  the analytical solution!

  \vfill

  Using samples from $ P(\theta \mid X) $, we can calculate MCMC estimators.
  
\end{frame}

\section{Markov Chain Monte Carlo}

\begin{frame}{MCMC}

  Markov Chain Monte Carlo (MCMC) is a method to sample from $
  P(\theta \mid X) $.

  \vfill

  Many different algorithms with different strengths and weaknesses.

  \vfill

  MCMC estimators will converge to true expectations (eventually).
  
\end{frame}

\begin{frame}{MCMC (cont.)}

  MCMC algorithms are not magic.
  
  \begin{itemize}
    \item The good: You can write custom samplers, develop highly
      flexible models, and do generally cool stuff.
    \item The bad: They cannot overcome issues with model specification,
      data collection or experimental design, etc.
    \item The ugly: You never know if they are working properly, only if
      they are not obviously broken. 
  \end{itemize}
  
\end{frame}

\begin{frame}[fragile]{Random Walk Metropolis Hastings}

<<echo = TRUE, size = 'tiny'>>=
RWmetroNorm <- function(x, prior_mu, prior_sd, known_sd = 1,
                        step_size = 0.1, iter = 100)
{
      samples <- numeric(iter)
      samples[1] <- rnorm(1, prior_mu, prior_sd)
      
      for(i in 2:iter){
          prop <- rnorm(1, samples[i - 1], step_size)

          cur_ll <- sum(dnorm(x, samples[i - 1], sd = known_sd, log = TRUE)) +
              dnorm(samples[i - 1], prior_mu, prior_sd, log = TRUE)
          prop_ll <- sum(dnorm(x, prop, sd = known_sd, log = TRUE)) +
              dnorm(prop, prior_mu, prior_sd, log = TRUE)

          jump_prob <- min(exp(prop_ll - cur_ll), 1)

          if(runif(1) < jump_prob){
              samples[i] <- prop
          } else {
              samples[i] <- samples[i -1]
          }
      }
      return(samples)
  }

@

\end{frame}

\begin{frame}[fragile]{Random Walk MH (cont.)}

<<echo=FALSE, fig = TRUE, out.width='80%'>>=
x <- rnorm(25, 10, 1)
RW_time <- system.time({ans <- RWmetroNorm(x = x, prior_mu = 8, prior_sd = 0.5, iter = 1e5)})

compareDens <- function(data, prior, post)
 {
     items <- list(density(data), density(prior), density(post))
     y_max <- max(sapply(items, function(x) max(x[['y']])))
     plot(items[[1]], type = 'n', ylim = c(0,y_max), main = '')
     sapply(1:3, function(i) lines(items[[i]], lty = i, lwd=2))
     legend('topright', legend = c('Likelihood', 'Prior', 'Posterior'),
            lty = 1:3, lwd=2)
 }

compareDens(rnorm(1e5, mean(x), sd(x)), rnorm(1e5, 8, 0.5), ans)

@ 

\end{frame}

\begin{frame}[fragile]{The 'fuzzy caterpillar'}

<<echo=FALSE, fig=TRUE, out.width='75%'>>=
coda::traceplot(as.mcmc(ans[1:1e4]), col = rgb(0,0,0,0.4))
@ 

\end{frame}

\begin{frame}[fragile]{JAGS: Just Another Gibbs Sampler}

  A popular MCMC sampler with cross-platform support.
  
<<size='small'>>=
mod.text <- '
model{
  for( i in 1:N ){
    x[i] ~ dnorm(mu, (1/known_sd ^2))
    }
  mu ~ dnorm(prior_mu, (1/prior_sd^2))
}'
@

<<echo=FALSE, include = FALSE, message = FALSE>>=
m <- jags.model(textConnection(mod.text),
                data = list(x = x, N = length(x),
                            known_sd = 1,
                            prior_mu = 8,
                            prior_sd = 0.5))
JAGS_time <- system.time({jags.ans <- coda.samples(m, 'mu', n.iter = 1e5)})

@ 
  
\end{frame}

\section{Comparing MCMC algorithms}

\begin{frame}[fragile]{Comparing MCMC algorithms}

  Which one is faster?
  
<<size = 'small'>>=
RW_time
JAGS_time
@ 
  
\end{frame}

\begin{frame}{Is faster what we want?}

  Not necessarily - how do we measure speed?

\end{frame}

\begin{frame}[fragile]{Comparing MCMC (cont.)}

  Effective size: The equivalent number of independent draws.
  
<<size='small'>>=
effectiveSize(ans)
effectiveSize(jags.ans)

@ 

\end{frame}

\begin{frame}{Comparing MCMC (cont.)}

  Effective size/time is often what we care about (efficiency).

  \vfill

  As the effective number of samples increases, the MCMC estimators
  will be converge to the true estimator.

  \vfill

  Unless high precision (low MCMC error) is needed, ~1000 effective
  samples is sufficient for most applications.

\end{frame}

\section{Troublesome posteriors}

\begin{frame}[fragile]{Let's break things!}

<<size = 'small'>>=
x2 <- rnorm(25, x, sd = 0.1)
y <- rnorm(25, x * 2, 0.5)

mod2.text <- '
model{
  for( i in 1:N ){
    y[i] ~ dnorm(beta1 * x[i] + beta2 * x2[i],
                 (1/known_sd ^2))
    }
  beta1 ~ dnorm(0, 1)
  beta2 ~ dnorm(0, 1)
}'
@

<<echo=FALSE, message = FALSE, include = FALSE>>=
jags_time <- system.time({
    m2 <- jags.model(textConnection(mod2.text),
                data = list(y = y, x = x, x2 = x2, N = length(x),
                            known_sd = 1), n.chains = 4)
    jags.ans2 <- coda.samples(m2, c('beta1', 'beta2'),
                              n.iter = 2000)
})

@   
  
\end{frame}  

\begin{frame}[fragile]{Difficult posteriors}

<<echo=FALSE, fig=TRUE, out.width='75%'>>=
par(mfrow = c(2,1))  
coda::traceplot(jags.ans2)
@ 

\end{frame}

\begin{frame}[fragile]{(Enter Stan)}

<<stan1, fig = TRUE, echo = FALSE, out.width = '75%', cache = TRUE>>=
stan_time <- system.time({stan.mod <- stan_glm(y ~ x + x2 - 1,
                                               prior = normal(),
                                               cores = 2L)})
plot(stan.mod, 'trace', pars = c('x','x2'), facet_args = list(nrow = 2))
@ 

\end{frame}

\begin{frame}[fragile]{Why does this break?}

<<fig=TRUE, echo = FALSE, out.width = '60%'>>=
pairs(stan.mod, pars = c('x','x2'))
@ 

\end{frame}

\begin{frame}[fragile]{What is the impact of this?}

<<size='small'>>=
effectiveSize(jags.ans2)
summary(stan.mod)[1:2,9]
@

\end{frame}

\begin{frame}[fragile]{MCMC efficiency revisited}

  JAGS is more efficient due to its speed, but requires many more
  draws.
  
<<size='small'>>=
effectiveSize(jags.ans2)/jags_time['elapsed']
summary(stan.mod)[1:2,9]/stan_time['elapsed']
@ 

\end{frame}

\begin{frame}[fragile]{Typical JAGS solution}

<<jags1, include = FALSE, echo = FALSE>>=
jags_time <- system.time({jags.ans2 <- coda.samples(m2, c('beta1', 'beta2'),
                                                    n.iter = 1e6, thin = 50)})
@

Sample a ton, then throw out all but every \textit{n}
draw.

100,000 iterations with a 50 draw thin:

<<size='small'>>=

effectiveSize(jags.ans2)

@ 
  
\end{frame}

\begin{frame}{A more difficult model to fit}

<<echo = FALSE, include = FALSE>>=
load('~/Ag_projects/breeding_analysis/data/mod_data.Rda')
n.level <- function(x){
    length(unique(x))
}
to.idx <- function(x){
    as.integer(factor(x))
}
dd <- with(mod_data, list(N = nrow(mod_data),
           n_cult = n.level(id),
           n_site = n.level(site),
           n_year = n.level(year),
           n_yr_site = n.level(yr_site_fact),
           cult = to.idx(id),
           site = to.idx(site),
           year = to.idx(year),
           siteyr = to.idx(yr_site_fact),
           yield = yield_cs))

@
 
  $$ y = \alpha + \beta_{site} + \beta_{cultivar} + \beta_{year} +
  \beta_{year:site} $$

  N = \Sexpr{dd['N']}\\
  n cult = \Sexpr{dd['n_cult']}\\
  n year = \Sexpr{dd['n_year']}\\
  n site = \Sexpr{dd['n_site']}\\
  n site:year = \Sexpr{dd['n_yr_site']}\\

\end{frame}

\begin{frame}[fragile]{In JAGS}
  
<<size = 'tiny'>>=
m3 <- 'model{
  for( i in 1:N ){
    mu[i] = alpha + b_site[site[i]] +
        b_cult[cult[i]] + b_year[year[i]] +
        b_siteyr[siteyr[i]]
    yield[i] ~ dnorm(mu[i],
                 (1/sigma ^2))
    }
  alpha ~ dnorm(0, 1)
  for(i in 1:n_site){
    b_site[i] ~ dnorm(0, (1/pow(tau[1],2)))}
  for(i in 1:n_cult){
    b_cult[i] ~ dnorm(0, (1/pow(tau[2],2)))}
  for(i in 1:n_year){
    b_year[i] ~ dnorm(0, (1/pow(tau[3],2)))}
  for(i in 1:n_yr_site){
    b_siteyr[i] ~ dnorm(0, (1/pow(tau[4],2)))}
  for(i in 1:4){
    tau[i] ~ dunif(0, 10)}
  sigma ~ dunif(0, 10)
}'

@

\end{frame}

\begin{frame}[fragile]{Efficiency}
<<stan2, echo = FALSE, include = FALSE, cache = TRUE>>=

jags.time2 <- system.time({
    mm <- jags.model(textConnection(m3), data = dd, n.chains=4)
    jags.fit <- coda.samples(mm, variable.names = 'b_cult', n.iter=1e3)
})

stan.time2 <- system.time({stan.fit <- stan_glmer(yield_cs ~ (1|site) +
                                                      (1|id) + (1|year) +
                                                      (1|yr_site_fact),
                                                  data = mod_data, cores = 2L, iter = 200)})

@

<<size = 'scriptsize', tidy = TRUE, tidy.opts=list(width.cutoff=60)>>=
effectiveSize(jags.fit)[1:5] /
    jags.time2['elapsed']

summary(stan.fit, regex_pars = ' id')[1:5,9]/stan.time2['elapsed']
@

\end{frame}

\section{Some caution required}

\begin{frame}{Diagnostics}

  $\hat{R}$ compares within and between chain variability

  \vfill

  N\textsubscript{eff} measures the effective draws a sample contains

  \vfill

  N\textsubscript{eff}/s measures efficiency

  \vfill

  N\textsubscript{eff}/draw is a different measure of efficiency

  \vfill

  Traceplots show how well chains mix (i.e., traverse the posterior)

  \vfill

  WAIC, PS-loo, Fraction of Bayesian missing information, etc...

\end{frame}

\begin{frame}{Warning!}

  MCMC is a powerful tool but:

  \vfill

  \textbf{OK diagnostics are a sign that nothing has gone
    obviously wrong, not a sign that things have gone right.}
  
\end{frame}

\begin{frame}{On that note...}

  Always run multiple chains, starting from different initial
  values. A good rule of thumb is minimum of 4 chains, more if
  possible.

  \vfill

  (I typically run 8-16 chains)

  \vfill

  More chains increases the chances that one will find a pathological
  region in the posterior, numeric instability, etc.

  \vfill

  \textbf{Do not just remove a poorly sampling chain! It is a sign
    something is wrong!}

\end{frame}

\section{Conclusion}
  
\begin{frame}{So why Stan?}

  Stan was built specifically to handle:

  \begin{enumerate}
  \item Difficult posteriors
  \item High dimensional problems
  \end{enumerate}
  
\end{frame}

\begin{frame}{Additional benefits}

  Stan is flexible*

  \vfill

  Under active development

  \vfill

  Large user base

  \vfill

  Cool add-on tools
  
\end{frame}

\begin{frame}{Conclusions}

  Bayesian inference for most non-trivial problems requires some way to
  sample from the posterior distribution, $ P(\theta \mid X)$.

  \vfill

  Samples can be generated using MCMC algorithms

  \vfill

  Algorithms differ in their speed and efficiency

  \vfill

  Although flexible and powerful, lots can go wrong
  
  
\end{frame}

\section{Demonstration}

\end{document}